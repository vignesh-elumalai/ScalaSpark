package org.inceptez.spark.sql

 import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import org.apache.spark.sql
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.SQLImplicits

case class schema2(name:String,amount:Int)

object test2 {
  
  def main(args:Array[String])
  {
    
    val spark=SparkSession.builder().appName("Testrun1").master("local[*]").getOrCreate();
    import spark.implicits._
    val sc=spark.sparkContext
    sc.setLogLevel("error")
    
   val df1=spark.read.csv("file:///home/hduser/Documents/data").toDF("name","id")
   
   val list1=sc.parallelize(Array(("a",2),("b",6),("c",3)))
   println(list1.map(x=>x._2).reduce(_ max _))
   
   val df2=list1.toDF("name","id")
   println(df2.columns)
   df2.createOrReplaceTempView("view1")
   spark.sql("select * from view1 a where a.id in (select max(b.id) from view1 b)").show()
    
   var li=List(1,2,3,4,5,6,7,8,9)
   var n=3
   var j=li.length/n
   for (i <- 1 to j)
   {
    li.take(n).foreach(print)
    println
    li=li.drop(n)
   }
  
  }
   
    
 
  
}
